{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2085688,"sourceType":"datasetVersion","datasetId":1250524},{"sourceId":204702,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":174656,"modelId":197009}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install moviepy --upgrade\n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:03.614914Z","iopub.execute_input":"2024-12-20T21:01:03.615269Z","iopub.status.idle":"2024-12-20T21:01:20.291333Z","shell.execute_reply.started":"2024-12-20T21:01:03.615237Z","shell.execute_reply":"2024-12-20T21:01:20.290369Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (2.1.1)\nRequirement already satisfied: decorator<6.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (5.1.1)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.34.1)\nRequirement already satisfied: imageio_ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.5.1)\nRequirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\nRequirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\nRequirement already satisfied: python-dotenv>=0.10 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.0.1)\nRequirement already satisfied: pillow<11.0,>=9.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (10.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy) (4.66.4)\nRequirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.6.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import List, Tuple, Sequence\n\nimport numpy as np\nfrom numpy import unravel_index\nfrom PIL import Image, ImageDraw, ImageFont\nfrom tqdm import tqdm, notebook\n\nfrom moviepy.video.io.ImageSequenceClip import ImageSequenceClip\n\nimport math\nfrom scipy.ndimage import gaussian_filter\n\nimport gc\nimport time\nimport random\nimport csv\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\nimport gdown\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:02:00.028783Z","iopub.execute_input":"2024-12-20T21:02:00.029155Z","iopub.status.idle":"2024-12-20T21:02:00.404453Z","shell.execute_reply.started":"2024-12-20T21:02:00.029123Z","shell.execute_reply":"2024-12-20T21:02:00.403757Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def get_num_clips(path: Path, game: int) -> int:\n    return len(list((path / f'game{game}/').iterdir()))\n\n\ndef get_game_clip_pairs(path: Path, games: List[int]) -> List[Tuple[int, int]]:\n    return [(game, c)  for game in games for c in range(1, get_num_clips(path, game) + 1)]\n\n\ndef load_clip_data(path: Path, game: int, clip: int, downscale: bool, quiet=False) -> np.ndarray:\n    if not quiet:\n        suffix = 'downscaled' if downscale else ''\n        print(f'loading clip data (game {game}, clip {clip}) {suffix}')\n    cache_path = path / 'cache'\n    cache_path.mkdir(exist_ok=True)\n    resize_code = '_ds2' if downscale else ''\n    cached_data_name = f'{game}_{clip}{resize_code}.npz'\n    if (cache_path / cached_data_name).exists():\n        clip_data = np.load(cache_path / cached_data_name)['clip_data']\n    else:\n        clip_path = path / f'game{game}/clip{clip}'\n        n_imgs = len(list(clip_path.iterdir())) - 1\n        imgs = [None] * n_imgs\n        for i in notebook.tqdm(range(n_imgs)):\n            img = Image.open(clip_path / f'{i:04d}.jpg')\n            if downscale:\n                img = img.resize((img.width // 2, img.height // 2),)\n            imgs[i] = np.array(img, dtype=np.uint8)\n        clip_data = np.stack(imgs)\n        cache_path.mkdir(exist_ok=True, parents=True)\n        np.savez_compressed(cache_path / cached_data_name, clip_data=clip_data)\n    return clip_data\n\n\ndef load_clip_labels(path: Path, game: int, clip: int, downscale: bool, quiet=False):\n    if not quiet:\n        print(f'loading clip labels (game {game}, clip {clip})')\n    clip_path = path / f'game{game}/clip{clip}'\n    labels = []\n    with open(clip_path / 'labels.csv') as csvfile:\n        lines = list(csv.reader(csvfile))\n        for line in lines[1:]:\n            values = np.array([-1 if i == '' else int(i) for i in line[1:]])\n            if downscale:\n                values[1] //= 2\n                values[2] //= 2\n            labels.append(values)\n    return np.stack(labels)\n\n\ndef load_clip(path: Path, game: int, clip: int, downscale: bool, quiet=False):\n    data = load_clip_data(path, game, clip, downscale, quiet)\n    labels = load_clip_labels(path, game, clip, downscale, quiet)\n    return data, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.165835Z","iopub.execute_input":"2024-12-20T21:01:22.166294Z","iopub.status.idle":"2024-12-20T21:01:22.178191Z","shell.execute_reply.started":"2024-12-20T21:01:22.166264Z","shell.execute_reply":"2024-12-20T21:01:22.177269Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def prepare_experiment(out_path: Path) -> Path:\n    out_path.mkdir(parents=True, exist_ok=True)\n    dirs = [d for d in out_path.iterdir() if d.is_dir() and d.name.startswith('exp_')]\n    experiment_id = max(int(d.name.split('_')[1]) for d in dirs) + 1 if dirs else 1\n    exp_path = out_path / f'exp_{experiment_id}'\n    exp_path.mkdir()\n    return exp_path\n\n\ndef ball_gauss_template(rad, sigma):\n    x, y = np.meshgrid(np.linspace(-rad, rad, 2 * rad + 1), np.linspace(-rad, rad, 2 * rad + 1)) \n    dst = np.sqrt(x * x + y * y) \n    gauss = np.exp(-(dst ** 2 / (2.0 * sigma ** 2)))     \n    return gauss\n\n\ndef create_masks(data: np.ndarray, labels: np.ndarray, resize):\n    rad = 64 #25\n    sigma = 10\n    if resize:\n        rad //= 2\n    ball = ball_gauss_template(rad, sigma)\n    n_frames = data.shape[0]\n    sh = rad\n    masks = []\n    for i in range(n_frames):\n        label = labels[i, ...] \n        frame = data[i, ...]\n        if 0 < label[0] < 3:\n            x, y = label[1:3]\n            mask = np.zeros((frame.shape[0] + 2 * rad + 2 * sh, frame.shape[1] + 2 * rad + 2 * sh), np.float32)\n            mask[y + sh : y + sh + 2 * rad + 1, x + sh : x + sh + 2 * rad + 1] = ball\n            mask = mask[rad + sh : -rad - sh, rad + sh : -rad - sh]\n            masks.append(mask)\n        else:\n            masks.append(np.zeros((frame.shape[0], frame.shape[1]), dtype=np.float32))\n    return np.stack(masks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.181295Z","iopub.execute_input":"2024-12-20T21:01:22.181682Z","iopub.status.idle":"2024-12-20T21:01:22.194397Z","shell.execute_reply.started":"2024-12-20T21:01:22.181640Z","shell.execute_reply":"2024-12-20T21:01:22.193728Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def _add_frame_number(frame: np.ndarray, number: int) -> np.ndarray:\n    fnt = ImageFont.load_default() # ImageFont.truetype(\"arial.ttf\", 25)\n    img = Image.fromarray(frame)\n    draw = ImageDraw.Draw(img)\n    draw.text((10, 10), f'frame {number}', font=fnt, fill=(255, 0, 255))\n    return np.array(img)\n\n\ndef _vis_clip(data: np.ndarray, lbls: np.ndarray, metrics: List[float] = None, ball_rad=5, color=(255, 0, 0), track_length=10):\n    print('perfoming clip visualization')\n    n_frames = data.shape[0]\n    frames_res = []\n    fnt = ImageFont.load_default() # ImageFont.truetype(\"arial.ttf\", 25)\n    for i in range(n_frames):\n        img = Image.fromarray(data[i, ...])\n        draw = ImageDraw.Draw(img)\n        txt = f'frame {i}'\n        if metrics is not None:\n            txt += f', SiBaTrAcc: {metrics[i]:.3f}'\n        draw.text((10, 10), txt, font=fnt, fill=(255, 0, 255))\n        label = lbls[i]\n        if label[0] != 0: # the ball is clearly visible\n            px, py = label[1], label[2]\n            draw.ellipse((px - ball_rad, py - ball_rad, px + ball_rad, py + ball_rad), outline=color, width=2)\n            for q in range(track_length):\n                if lbls[i-q-1][0] == 0:\n                    break\n                if i - q > 0:\n                    draw.line((lbls[i - q - 1][1], lbls[i - q - 1][2], lbls[i - q][1], lbls[i - q][2]), fill=color)                \n        frames_res.append(np.array(img))\n    return frames_res\n\n\ndef _save_clip(frames: Sequence[np.ndarray], path: Path, fps):\n    assert path.suffix in ('.mp4', '.gif')\n    clip = ImageSequenceClip(frames, fps=fps)\n    if path.suffix == '.mp4':\n        clip.write_videofile(str(path), fps=fps, logger=None)\n    else:\n        clip.write_gif(str(path), fps=fps, logger=None)\n\n\ndef _to_yellow_heatmap(frame: np.ndarray, pred_frame: np.ndarray, alpha=0.4):\n    img = Image.fromarray((frame * alpha).astype(np.uint8))\n    maskR = (pred_frame * (1 - alpha) * 255).astype(np.uint8)\n    maskG = (pred_frame * (1 - alpha) * 255).astype(np.uint8)\n    maskB = np.zeros_like(maskG, dtype=np.uint8)\n    mask = np.stack([maskR, maskG, maskB], axis=-1)\n    return img + mask\n\n\ndef _vis_pred_heatmap(data_full: np.ndarray, pred_prob: np.ndarray, display_frame_number):\n    n_frames = data_full.shape[0]\n    v_frames = []\n    for i in range(n_frames):\n        frame = data_full[i, ...]\n        pred = pred_prob[i, ...]\n        hm = _to_yellow_heatmap(frame, pred)\n        if display_frame_number:\n            hm = _add_frame_number(hm, i)\n        v_frames.append(hm)\n    return v_frames\n\n\ndef visualize_prediction(data_full: np.ndarray, labels_pr: np.ndarray, save_path: Path, name: str, metrics=None, fps=15):\n    with open(save_path / f'{name}.txt', mode='w') as f:\n        if metrics is not None:\n            f.write(f'SiBaTrAcc: {metrics[-1]} \\n')\n        for i in range(labels_pr.shape[0]):\n            f.write(f'frame {i}: {labels_pr[i, 0]}, {labels_pr[i, 1]}, {labels_pr[i, 2]} \\n')\n\n    v = _vis_clip(data_full, labels_pr, metrics)\n    _save_clip(v, save_path / f'{name}.mp4', fps=fps)\n\n\ndef visualize_prob(data: np.ndarray, pred_prob: np.ndarray, save_path: Path, name: str, frame_number=True, fps=15):\n    v_pred = _vis_pred_heatmap(data, pred_prob, frame_number)\n    _save_clip(v_pred, save_path / f'{name}_prob.mp4', fps=fps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.195437Z","iopub.execute_input":"2024-12-20T21:01:22.195732Z","iopub.status.idle":"2024-12-20T21:01:22.212498Z","shell.execute_reply.started":"2024-12-20T21:01:22.195705Z","shell.execute_reply":"2024-12-20T21:01:22.211605Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class DataGenerator:\n\n    def __init__(self, path: Path, games: List[int], stack_s, downscale, pool_s=30, pool_update_s=10, pool_autoupdate=True, quiet=False) -> None:\n        self.path = path\n        self.stack_s = stack_s\n        self.downscale = downscale\n        self.pool_size = pool_s\n        self.pool_update_size = pool_update_s\n        self.pool_autoupdate = pool_autoupdate\n        self.quiet = quiet\n        self.data = []\n        self.masks = []\n\n        self.frames_in_pool = 0\n        self.produced_frames = 0\n        self.game_clip_pairs = get_game_clip_pairs(path, list(set(games)))\n        self.game_clip_pairs_loaded = []\n        self.game_clip_pairs_not_loaded = list.copy(self.game_clip_pairs) \n        self.pool = {}\n\n        self._first_load()\n\n    def _first_load(self):\n        # --- if all clips can be placed into pool at once, there is no need to refresh pool at all ---\n        if len(self.game_clip_pairs) <= self.pool_size:\n            for gcp in self.game_clip_pairs:\n                self._load(gcp)\n            self.game_clip_pairs_loaded = list.copy(self.game_clip_pairs)\n            self.game_clip_pairs_not_loaded.clear()\n            self.pool_autoupdate = False\n        else:\n            self._load_to_pool(self.pool_size)        \n        self._update_clip_weights()\n\n    def _load(self, game_clip_pair):\n        game, clip = game_clip_pair\n        data, labels = load_clip(self.path, game, clip, self.downscale, quiet=self.quiet)\n        masks = create_masks(data, labels, self.downscale)\n        weight = data.shape[0] if data.shape[0] >= self.stack_s else 0\n        self.pool[game_clip_pair] = (data, labels, masks, weight)\n        self.frames_in_pool += data.shape[0] - self.stack_s + 1\n        # print(f'items in pool: {len(self.pool)} - {self.pool.keys()}')\n\n    def _remove(self, game_clip_pair):\n        value = self.pool.pop(game_clip_pair)\n        self.frames_in_pool -= value[0].shape[0] - self.stack_s + 1\n        del value\n        # print(f'items in pool: {len(self.pool)} - {self.pool.keys()}')\n\n    def _update_clip_weights(self):\n        weights = [self.pool[pair][-1] for pair in self.game_clip_pairs_loaded]\n        tw = sum(weights)\n        self.clip_weights = [w / tw for w in weights]\n        # print(f'clip weights: {self.clip_weights}')\n\n    def _remove_from_pool(self, n):\n        # --- remove n random clips from pool ---\n        if len(self.game_clip_pairs_loaded) >= n:\n            remove_pairs = random.sample(self.game_clip_pairs_loaded, n)\n            for pair in remove_pairs:\n                self._remove(pair)\n                self.game_clip_pairs_loaded.remove(pair)\n                self.game_clip_pairs_not_loaded.append(pair)\n            gc.collect()\n\n    def _load_to_pool(self, n):\n        # --- add n random clips to pool ---\n        gc.collect()\n        add_pairs = random.sample(self.game_clip_pairs_not_loaded, n)\n        for pair in add_pairs:\n            self._load(pair)\n            self.game_clip_pairs_not_loaded.remove(pair)\n            self.game_clip_pairs_loaded.append(pair)\n\n    def update_pool(self):\n        self._remove_from_pool(self.pool_update_size)\n        self._load_to_pool(self.pool_update_size)\n        self._update_clip_weights()\n\n    def get_random_stack(self):\n        pair_idx = np.random.choice(len(self.game_clip_pairs_loaded), 1, p=self.clip_weights)[0]\n        game_clip_pair = self.game_clip_pairs_loaded[pair_idx]\n        d, _, m, _ = self.pool[game_clip_pair]\n        start = np.random.choice(d.shape[0] - self.stack_s, 1)[0]\n        frames_stack = d[start : start + self.stack_s, ...]\n        frames_stack = np.squeeze(np.split(frames_stack, indices_or_sections=self.stack_s, axis=0))\n        frames_stack = np.concatenate(frames_stack, axis=-1)\n        mask = m[start + self.stack_s - 1, ...]\n        return frames_stack, mask\n\n    def get_random_batch(self, batch_s):\n        imgs, masks = [], []\n        while len(imgs) < batch_s:\n            frames_stack, mask = self.get_random_stack()\n            imgs.append(frames_stack)\n            masks.append(mask)\n        if self.pool_autoupdate:\n            self.produced_frames += batch_s\n            # print(f'produced frames: {self.produced_frames} from {self.frames_in_pool}')\n            if self.produced_frames >= self.frames_in_pool:\n                self.update_pool()\n                self.produced_frames = 0\n        return np.stack(imgs), np.stack(masks)\n\n    def random_g(self, batch_s):\n        while True:\n            imgs_batch, masks_batch = self.get_random_batch(batch_s)\n            yield imgs_batch, masks_batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.213832Z","iopub.execute_input":"2024-12-20T21:01:22.214094Z","iopub.status.idle":"2024-12-20T21:01:22.235366Z","shell.execute_reply.started":"2024-12-20T21:01:22.214068Z","shell.execute_reply":"2024-12-20T21:01:22.234595Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Metrics:\n\n    @staticmethod\n    def position_error(label_gt: np.ndarray, label_pr: np.ndarray, step=8, alpha=1.5, e1=5, e2=5):\n        # gt codes:\n        # 0 - the ball is not within the image\n        # 1 - the ball can easily be identified\n        # 2 - the ball is in the frame, but is not easy to identify\n        # 3 - the ball is occluded\n        if label_gt[0] != 0 and label_pr[0] == 0:\n            return e1\n        if label_gt[0] == 0 and label_pr[0] != 0:\n            return e2\n        dist = math.sqrt((label_gt[1] - label_pr[1]) ** 2 + (label_gt[2] - label_pr[2]) ** 2)\n        pe = math.floor(dist / step) ** alpha\n        pe = min(pe, 5)\n        return pe\n\n    @staticmethod\n    def evaluate_predictions(labels_gt, labels_pr) -> Tuple[List[float], float]:\n        pe = [Metrics.position_error(labels_gt[i, ...], labels_pr[i, ...]) for i in range(len(labels_gt))]\n        SIBATRACC = []\n        for i, _ in enumerate(pe):\n            SIBATRACC.append(1 - sum(pe[: i + 1]) / ((i + 1) * 5))\n        SIBATRACC_total = 1 - sum(pe) / (len(labels_gt) * 5)\n        return SIBATRACC, SIBATRACC_total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.236213Z","iopub.execute_input":"2024-12-20T21:01:22.236475Z","iopub.status.idle":"2024-12-20T21:01:22.250631Z","shell.execute_reply.started":"2024-12-20T21:01:22.236451Z","shell.execute_reply":"2024-12-20T21:01:22.249889Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, pad=1, stride=1, bias=True):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=pad, bias=bias),\n            nn.ReLU(),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\nclass Net(nn.Module):\n    def __init__(self, out_channels=256):\n        super().__init__()\n        self.out_channels = out_channels\n\n        self.conv1 = ConvBlock(in_channels=9, out_channels=64)\n        self.conv2 = ConvBlock(in_channels=64, out_channels=64)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = ConvBlock(in_channels=64, out_channels=128)\n        self.conv4 = ConvBlock(in_channels=128, out_channels=128)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv5 = ConvBlock(in_channels=128, out_channels=256)\n        self.conv6 = ConvBlock(in_channels=256, out_channels=256)\n        self.conv7 = ConvBlock(in_channels=256, out_channels=256)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv8 = ConvBlock(in_channels=256, out_channels=512)\n        self.conv9 = ConvBlock(in_channels=512, out_channels=512)\n        self.conv10 = ConvBlock(in_channels=512, out_channels=512)\n        self.ups1 = nn.Upsample(scale_factor=2)\n        self.conv11 = ConvBlock(in_channels=512, out_channels=256)\n        self.conv12 = ConvBlock(in_channels=256, out_channels=256)\n        self.conv13 = ConvBlock(in_channels=256, out_channels=256)\n        self.ups2 = nn.Upsample(scale_factor=2)\n        self.conv14 = ConvBlock(in_channels=256, out_channels=128)\n        self.conv15 = ConvBlock(in_channels=128, out_channels=128)\n        self.ups3 = nn.Upsample(scale_factor=2)\n        self.conv16 = ConvBlock(in_channels=128, out_channels=64)\n        self.conv17 = ConvBlock(in_channels=64, out_channels=64)\n        self.conv18 = ConvBlock(in_channels=64, out_channels=self.out_channels)\n\n        self.softmax = nn.Softmax(dim=1)\n        self._init_weights()\n                  \n    def forward(self, x, testing=False):\n        batch_size = x.size(0)\n        x = self.conv1(x)\n        x = self.conv2(x)    \n        x = self.pool1(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.pool2(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = self.conv7(x)\n        x = self.pool3(x)\n        x = self.conv8(x)\n        x = self.conv9(x)\n        x = self.conv10(x)\n        x = self.ups1(x)\n        x = self.conv11(x)\n        x = self.conv12(x)\n        x = self.conv13(x)\n        x = self.ups2(x)\n        x = self.conv14(x)\n        x = self.conv15(x)\n        x = self.ups3(x)\n        x = self.conv16(x)\n        x = self.conv17(x)\n        x = self.conv18(x)\n        # x = self.softmax(x)\n        out = x.reshape(batch_size, self.out_channels, -1)\n        if testing:\n            out = self.softmax(out)\n        return out                       \n    \n    def _init_weights(self):\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d):\n                nn.init.uniform_(module.weight, -0.05, 0.05)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0)\n\n            elif isinstance(module, nn.BatchNorm2d):\n                nn.init.constant_(module.weight, 1)\n                nn.init.constant_(module.bias, 0)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.252001Z","iopub.execute_input":"2024-12-20T21:01:22.252332Z","iopub.status.idle":"2024-12-20T21:01:22.266519Z","shell.execute_reply.started":"2024-12-20T21:01:22.252295Z","shell.execute_reply":"2024-12-20T21:01:22.265835Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def postprocess(feature_map, scale=2):\n    feature_map *= 255\n    feature_map = feature_map.reshape((360, 640))\n    feature_map = feature_map.astype(np.uint8)\n    ret, heatmap = cv2.threshold(feature_map, 127, 255, cv2.THRESH_BINARY)\n    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=2,\n                               maxRadius=7)\n    #plt.imshow(heatmap, cmap='gray')\n    x,y = None, None\n    if circles is not None:\n        if len(circles) == 1:\n            x = circles[0][0][0]*scale\n            y = circles[0][0][1]*scale\n    return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.267474Z","iopub.execute_input":"2024-12-20T21:01:22.267769Z","iopub.status.idle":"2024-12-20T21:01:22.278829Z","shell.execute_reply.started":"2024-12-20T21:01:22.267730Z","shell.execute_reply":"2024-12-20T21:01:22.277939Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train(model, train_gen, optimizer, device, epoch, max_iters=200, batch_s = 2):\n    losses = []\n    criterion = nn.CrossEntropyLoss()\n    for _ in range(10):\n        stack, masks = train_gen.get_random_stack()\n        optimizer.zero_grad()\n        model.train()\n        print(batches.shape)\n        imgs = stack.astype(np.float32) / 255.0\n        imgs = np.rollaxis(imgs, 2, 0)\n        \n        imgs = torch.from_numpy(imgs).float().to(device)\n        print(imgs.shape)\n        out = model(imgs).cpu().detach().numpy()\n        out = out * 255\n        out = out.reshape((360, 640))\n        out = out.astype(np.uint8)\n        _, out = cv2.threshold(out, 127, 255, cv2.THRESH_BINARY)\n        out = torch.tensor(out).to(device)\n        \n        gt = torch.tensor(masks, dtype=torch.long, device=device)\n        loss = criterion(out, gt)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        print('train | epoch = {}, loss = {}'.format(epoch, round(loss.item(), 6)))\n        losses.append(loss.item())\n        \n        if iter_id > max_iters - 1:\n            break\n        \n    return np.mean(losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:01:22.280784Z","iopub.execute_input":"2024-12-20T21:01:22.281043Z","iopub.status.idle":"2024-12-20T21:01:22.295089Z","shell.execute_reply.started":"2024-12-20T21:01:22.281018Z","shell.execute_reply":"2024-12-20T21:01:22.294336Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class SuperTrackingModel:\n\n    def __init__(self, batch_s = 2, stack_s = 3, out_path = '/kaggle/working/', downscale = True):\n        self.batch_s = batch_s\n        self.stack_s = stack_s\n        self.out_path = out_path\n        self.downscale = downscale\n        self.device = 'cuda'\n        self.net = Net().to(self.device)\n\n    def load(self):\n        name = 'best'\n        name_to_id_dict = {\n                    'best': 'https://drive.google.com/file/d/1VSDYCCbCO2qU6f-_s66c1QeZ297UEB0_/view?usp=sharing'\n                }\n        output = f'{name}.pt'\n        gdown.download(name_to_id_dict[name], output, fuzzy=True)\n\n        self.net.load_state_dict(torch.load(output, weights_only=True))\n        self.net.eval()\n        print('Running stub for loading model ...')\n        time.sleep(1)\n        print('Loading model done.')\n\n    def predict_on_batch(self, batch: np.ndarray):\n        imgs = batch.astype(np.float32) / 255.0\n        \n        imgs = np.rollaxis(imgs, 3, 1)\n        reses = self.net(torch.from_numpy(imgs).float().to(self.device)).cpu().detach().numpy()\n        \n        return reses\n        \n    def _predict_prob_on_clip(self, clip: np.ndarray) -> np.ndarray:\n        print('doing predictions')\n        n_frames = clip.shape[0]\n        # --- get stacks ---\n        stacks = []\n        for i in range(n_frames - self.stack_s + 1):\n            stack = clip[i : i + self.stack_s, ...]\n            stack = np.squeeze(np.split(stack, self.stack_s, axis=0))\n            stack = np.concatenate(stack, axis=-1)\n            stacks.append(stack)\n        # --- round to batch size ---\n        add_stacks = 0\n        while len(stacks) % self.batch_s != 0:\n            stacks.append(stacks[-1])\n            add_stacks += 1\n        # --- group into batches ---\n        batches = []\n        for i in range(len(stacks) // self.batch_s):\n            batch = np.stack(stacks[i * self.batch_s : (i + 1) * self.batch_s])\n            batches.append(batch)\n        stacks.clear()\n        # --- perform predictions ---\n        predictions = []\n        for batch in batches:\n            print(batch.shape)\n            pred = np.squeeze(self.predict_on_batch(batch))\n            predictions.append(pred)\n        # --- crop back to source length ---\n        predictions = np.concatenate(predictions, axis=0)\n        if (add_stacks > 0):\n            predictions = predictions[:-add_stacks, ...]\n        batches.clear()\n        # --- add (stack_s - 1) null frames at the begining ---\n        start_frames = np.zeros((stack_s - 1, predictions.shape[1], predictions.shape[2]), dtype=np.float32)\n        predictions = np.concatenate((start_frames, predictions), axis=0)\n        print('predictions are made')        \n        return predictions\n\n    def get_labels_from_prediction(self, pred_prob: np.ndarray, upscale_coords: bool) -> np.ndarray:\n        n_frames = pred_prob.shape[0]\n        coords = np.zeros([n_frames, 3])\n        for i in range(n_frames):\n            out = pred_prob[i].argmax(dim=1)\n            x, y = postprocess(out)\n            if x is None or y is None:\n                coords[i] = np.array([0, 0, 0])\n            else:\n                coords[i] = np.array([1, int(x / 2), int(y / 2)])\n        return coords\n\n    def predict(self, clip: np.ndarray, upscale_coords=True) -> tuple[np.ndarray, np.ndarray]:\n        prob_pr = self._predict_prob_on_clip(clip)\n        labels_pr = self.get_labels_from_prediction(prob_pr, upscale_coords)\n        return labels_pr, prob_pr\n\n    def test(self,  data_path = '../input/tennistrackingassignment/train/', games = [1],do_visualization=False, test_name='test'):\n        game_clip_pairs = get_game_clip_pairs(data_path, games)\n        SIBATRACC_vals = []\n        for game, clip in game_clip_pairs:\n            print(game, clip)\n            data = load_clip_data(data_path, game, clip, downscale=self.downscale)\n            if do_visualization:\n                data_full = load_clip_data(data_path, game, clip, downscale=False) if self.downscale else data\n            labels_gt = load_clip_labels(data_path, game, clip, downscale=False)\n            labels_pr, prob_pr = self.predict(data)\n            SIBATRACC_per_frame, SIBATRACC_total = Metrics.evaluate_predictions(labels_gt, labels_pr)\n            SIBATRACC_vals.append(SIBATRACC_total)\n            if do_visualization:\n                visualize_prediction(data_full, labels_pr, self.out_path, f'{test_name}_g{game}_c{clip}', SIBATRACC_per_frame)\n                visualize_prob(data, prob_pr, self.out_path, f'{test_name}_g{game}_c{clip}')\n                del data_full\n            del data, labels_gt, labels_pr, prob_pr\n            gc.collect()\n        SIBATRACC_final = sum(SIBATRACC_vals) / len(SIBATRACC_vals)\n        return SIBATRACC_final\n\n    def train(self, param_1=None, param_2=None, param_3=None, param_4=None, param_5=None, param_6=None):\n        print('Running stub for training model...')\n        train_gen = DataGenerator(Path('../input/tennistrackingassignment/train/'), [1, 2, 3, 4, 5, 6], stack_s=stack_s, downscale=True, pool_s=10, pool_update_s=4, quiet=True)\n        optimizer = optim.Adadelta(self.net.parameters(), lr=0.01)\n        for epoch in range(50):\n            train_loss = train(self.net, train_gen, optimizer, self.device, epoch)\n            print('train loss = {}'.format(train_loss))\n        time.sleep(2)\n        print('training done.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:07:35.291867Z","iopub.execute_input":"2024-12-20T21:07:35.292438Z","iopub.status.idle":"2024-12-20T21:07:35.310974Z","shell.execute_reply.started":"2024-12-20T21:07:35.292404Z","shell.execute_reply":"2024-12-20T21:07:35.309894Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = SuperTrackingModel()\nmodel.load()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T21:07:35.550335Z","iopub.execute_input":"2024-12-20T21:07:35.550931Z","iopub.status.idle":"2024-12-20T21:07:40.912350Z","shell.execute_reply.started":"2024-12-20T21:07:35.550901Z","shell.execute_reply":"2024-12-20T21:07:40.911406Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1VSDYCCbCO2qU6f-_s66c1QeZ297UEB0_\nTo: /kaggle/working/best.pt\n100%|██████████| 42.9M/42.9M [00:00<00:00, 101MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Running stub for loading model ...\nLoading model done.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}